# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bUD3QgVYtnicQR0b8JLZMprirRPM_tzM
"""

!pip install scrapy

import scrapy
from scrapy.crawler import CrawlerProcess
import pandas as pd


class WikiSpider(scrapy.Spider):
    name = 'wikispider'
    start_urls = [
        'https://ru.wikipedia.org/wiki/200_лучших_романов_по_версии_Би-би-си']

    def parse(self, response):
        base_url = 'https://ru.wikipedia.org'
        for book in response.css('table tr:not(:first-child)'):
            title = book.css('td:nth-child(2) a::text').get()
            author = book.css('td:nth-child(3) a::text').get()
            country = book.css('td:nth-child(4) a::text').get()
            link = book.css('td:nth-child(2) a::attr(href)').get()
            yield response.follow(url=base_url + link, callback=self.parse_book, cb_kwargs=dict(title=title, author=author, country=country))

    def parse_book(self, response, title, author, country):
        genre = response.css('th:contains("Жанр") + td span::text').get()

        book_data = {
            'title': title,
            'author': author,
            'country': country,
            'genre': genre,
            }


        yield book_data

process = CrawlerProcess({
    'FEED_FORMAT': 'csv',
    'FEED_URI': 'output1.csv'
})
process.crawl(WikiSpider)
process.start()